application.logging.dir = C:/Users/carlo/Cloudera/Log/AuroraScala
application.logging.filename = ${application.logging.dir}/dataload.log
application.logging.appender.layout = org.apache.log4j.PatternLayout
application.logging.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} [%p] %C.%M: %m%n

# APPENDERS
# stdout
log4j.appender.stdout = org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Threshold = INFO
log4j.appender.stdout.Target = System.out
log4j.appender.stdout.layout = ${application.logging.appender.layout}
log4j.appender.stdout.layout.ConversionPattern = ${application.logging.layout.pattern}

# rolling_file
log4j.appender.rolling_file = org.apache.log4j.DailyRollingFileAppender
log4j.appender.rolling_file.DatePattern = '.'yyyy_MM_dd
log4j.appender.rolling_file.Threshold = INFO
log4j.appender.rolling_file.append = true
log4j.appender.rolling_file.File = ${application.logging.filename}
log4j.appender.rolling_file.layout = ${application.logging.appender.layout}
log4j.appender.rolling_file.layout.ConversionPattern = ${application.logging.layout.pattern}

# LOGGERS
log4j.rootLogger = INFO, stdout, rolling_file
log4j.logger.it.luca = INFO, stdout, rolling_file
log4j.logger.org.apache.hadoop = WARN, stdout, rolling_file
log4j.logger.org.apache.spark = WARN, stdout, rolling_file
log4j.logger.org.spark_project.jetty = WARN, stdout, rolling_file

# avoids Windows-related errors when ShutdownHookManager
# attempts to delete spark temporary working directory
log4j.logger.org.apache.spark.util.ShutdownHookManager = OFF
log4j.logger.org.apache.spark.SparkEnv = ERROR

# LOGGER ADDITIVITY
log4j.additivity.it.luca = false
log4j.additivity.org.apache.hadoop = false
log4j.additivity.org.apache.spark = false
log4j.additivity.org.spark_project.jetty = false